import os
import json
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm
from model import resnet101

def get_data_generators(train_dir, validation_dir, im_height, im_width, batch_size, pre_function):
    train_image_generator = ImageDataGenerator(horizontal_flip=True, preprocessing_function=pre_function)
    validation_image_generator = ImageDataGenerator(preprocessing_function=pre_function)

    train_data_gen = train_image_generator.flow_from_directory(
        directory=train_dir,
        batch_size=batch_size,
        shuffle=True,
        target_size=(im_height, im_width),
        class_mode='categorical'
    )

    val_data_gen = validation_image_generator.flow_from_directory(
        directory=validation_dir,
        batch_size=batch_size,
        shuffle=False,
        target_size=(im_height, im_width),
        class_mode='categorical'
    )

    return train_data_gen, val_data_gen

def create_model(num_classes):
    feature = resnet101(num_classes=5, include_top=False)
    model = tf.keras.Sequential([
        feature,
        tf.keras.layers.GlobalAvgPool2D(),
        tf.keras.layers.Dropout(rate=0.5),
        tf.keras.layers.Dense(1024, activation="relu"),
        tf.keras.layers.Dropout(rate=0.5),
        tf.keras.layers.Dense(num_classes),
        tf.keras.layers.Softmax()
    ])
    return model

def main():
    # 设定dataset下的 "train"、"test"、"validation"
    data_root = os.path.abspath(os.path.join(os.getcwd(), "../"))  # get data root path
    image_path = os.path.join(data_root, "dataset")
    train_dir = os.path.join(image_path, "train")
    validation_dir = os.path.join(image_path, "validation")
    assert os.path.exists(train_dir), f"cannot find {train_dir}"
    assert os.path.exists(validation_dir), f"cannot find {validation_dir}"

    im_height = 120
    im_width = 150
    batch_size = 16
    epochs = 30
    num_classes = 2

    # 此处计算的均值在灰度图中将会得到三个相同的灰度均值
    # 此处参考的是ResNet花分类办法
    # 输入的图片集合必须保证为三通道RGB
    # 可以通过"gray2rgb"进行直接转换，不会损失任何信息
    # 亦或是通过自定义model文件去除这一步骤
    _R_MEAN, _G_MEAN, _B_MEAN = 169.5316498, 143.2272235, 107.2475178

    def pre_function(img):
        return img - [_R_MEAN, _G_MEAN, _B_MEAN]

    train_data_gen, val_data_gen = get_data_generators(train_dir, validation_dir, im_height, im_width, batch_size, pre_function)
    total_train, total_val = train_data_gen.n, val_data_gen.n

    # get class dict and save to json
    class_indices = train_data_gen.class_indices
    inverse_dict = {val: key for key, val in class_indices.items()}
    json_str = json.dumps(inverse_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    print(f"using {total_train} images for training, {total_val} images for validation.")

    model = create_model(num_classes)
    model.build((None, im_height, im_width, 3))
    model.summary()

    # using keras low level api for training
    # The learning rate is 0.00002 is based on 727,328 trainning samples
    # And 241,793 validation samples
    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00002)  # Change learning rate based on your dataset

    train_loss = tf.keras.metrics.Mean(name='train_loss')
    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')
    val_loss = tf.keras.metrics.Mean(name='val_loss')
    val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')

    @tf.function
    def train_step(images, labels):
        with tf.GradientTape() as tape:
            output = model(images, training=True)
            loss = loss_object(labels, output)
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        train_loss(loss)
        train_accuracy(labels, output)

    @tf.function
    def val_step(images, labels):
        output = model(images, training=False)
        loss = loss_object(labels, output)
        val_loss(loss)
        val_accuracy(labels, output)

    best_val_acc = 0.
    for epoch in range(epochs):
        train_loss.reset_states()
        train_accuracy.reset_states()
        val_loss.reset_states()
        val_accuracy.reset_states()

        # train
        train_bar = tqdm(range(total_train // batch_size), desc=f"Train Epoch {epoch+1}/{epochs}")
        for _ in train_bar:
            images, labels = next(train_data_gen)
            train_step(images, labels)
            train_bar.set_postfix({'loss': f"{train_loss.result():.5f}", 'acc': f"{train_accuracy.result():.5f}"})

        # validate
        val_bar = tqdm(range(total_val // batch_size), desc=f"Valid Epoch {epoch+1}/{epochs}")
        for _ in val_bar:
            test_images, test_labels = next(val_data_gen)
            val_step(test_images, test_labels)
            val_bar.set_postfix({'loss': f"{val_loss.result():.5f}", 'acc': f"{val_accuracy.result():.5f}"})

        # only save best weights
        if val_accuracy.result() > best_val_acc:
            best_val_acc = val_accuracy.result()
            model.save_weights("./save_weights/627.ckpt", save_format="tf")

if __name__ == '__main__':
    main()